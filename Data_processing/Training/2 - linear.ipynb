{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_photos(directory):\n",
    "    images = []\n",
    "    labels1 = []\n",
    "    labels2 = []\n",
    "    for name in listdir(directory):\n",
    "        filename = directory + '/' + name\n",
    "        # convert image to gray\n",
    "        #img = Image.open(filename).convert('L')\n",
    "        #img.save(filename)\n",
    "        # load an image from file\n",
    "        image = load_img(filename, target_size=(160, 128))\n",
    "        # convert the image pixels to a numpy array\n",
    "        image = img_to_array(image)\n",
    "        # get image id + labels\n",
    "        labels1.append(float(name.split('_')[0].split('-')[0]))\n",
    "        labels2.append(float(name.split('_')[0].split('-')[1]))\n",
    "        images.append(image)\n",
    "    return images, labels1, labels2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Images and labels for training: 199\n",
      "Loaded Images and labels for validation: 150\n"
     ]
    }
   ],
   "source": [
    "# load images from both train and test groups\n",
    "directory = '../data/Patate_Pics/Training-Less-Sorted'\n",
    "images, labels1, labels2 = load_photos(directory)\n",
    "nb_images = len(images)\n",
    "print('Loaded Images and labels for training: %d' % nb_images)\n",
    "directory = '../data/Patate_Pics/Validation'\n",
    "images_val, labels1_val, labels2_val = load_photos(directory)\n",
    "nb_images_val = len(images_val)\n",
    "print('Loaded Images and labels for validation: %d' % nb_images_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#normalise datas\n",
    "images = np.array(images)\n",
    "images /= 255\n",
    "images_val = np.array(images_val)\n",
    "images_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to np.array\n",
    "labels1 = np.array(labels1)\n",
    "labels2 = np.array(labels2)\n",
    "labels1_val = np.array(labels1_val)\n",
    "labels2_val = np.array(labels2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.29,  0.31,  0.33,  0.35,  0.35,  0.35,  0.38,  0.4 ,  0.43,\n",
       "         0.44,  0.47,  0.47,  0.47,  0.48,  0.48,  0.49,  0.51,  0.51,\n",
       "         0.51,  0.51,  0.51,  0.51,  0.52,  0.52,  0.52,  0.52,  0.53,\n",
       "         0.53,  0.53,  0.54,  0.54,  0.54,  0.55,  0.55,  0.55,  0.55,\n",
       "         0.56,  0.56,  0.56,  0.56,  0.56,  0.56,  0.56,  0.57,  0.57,\n",
       "         0.57,  0.57,  0.58,  0.58,  0.58,  0.58,  0.58,  0.58,  0.58,\n",
       "         0.58,  0.59,  0.59,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,\n",
       "         0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,\n",
       "         0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.61,  0.61,\n",
       "         0.61,  0.61,  0.61,  0.61,  0.61,  0.61,  0.61,  0.61,  0.61,\n",
       "         0.61,  0.61,  0.61,  0.62,  0.62,  0.62,  0.62,  0.62,  0.62,\n",
       "         0.62,  0.63,  0.63,  0.63,  0.63,  0.63,  0.63,  0.64,  0.64,\n",
       "         0.64,  0.64,  0.64,  0.64,  0.65,  0.65,  0.65,  0.65,  0.65,\n",
       "         0.65,  0.66,  0.66,  0.66,  0.66,  0.66,  0.66,  0.66,  0.66,\n",
       "         0.66,  0.66,  0.67,  0.67,  0.67,  0.68,  0.68,  0.68,  0.68,\n",
       "         0.68,  0.69,  0.69,  0.69,  0.69,  0.69,  0.69,  0.69,  0.69,\n",
       "         0.69,  0.69,  0.69,  0.69,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.7 ,\n",
       "         0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.71,  0.71,  0.71,\n",
       "         0.71,  0.72,  0.72,  0.72,  0.72,  0.73,  0.73,  0.73,  0.73,\n",
       "         0.73,  0.73,  0.73,  0.73,  0.73,  0.73,  0.74,  0.74,  0.74,\n",
       "         0.74,  0.74,  0.74,  0.74,  0.74,  0.74,  0.74,  0.74,  0.74,\n",
       "         0.74,  0.75,  0.75,  0.75,  0.75,  0.75,  0.75,  0.75,  0.75,  0.75]),\n",
       " array([ 0.3 ,  0.55,  0.57,  0.33,  0.65,  0.71,  0.71,  0.64,  0.66,\n",
       "         0.65,  0.39,  0.51,  0.72,  0.74,  0.74,  0.66,  0.57,  0.59,\n",
       "         0.5 ,  0.5 ,  0.71,  0.73,  0.35,  0.59,  0.5 ,  0.61,  0.33,\n",
       "         0.62,  0.69,  0.35,  0.49,  0.55,  0.43,  0.5 ,  0.69,  0.73,\n",
       "         0.35,  0.55,  0.56,  0.61,  0.67,  0.69,  0.71,  0.55,  0.55,\n",
       "         0.57,  0.7 ,  0.52,  0.53,  0.55,  0.62,  0.68,  0.68,  0.71,\n",
       "         0.74,  0.41,  0.48,  0.35,  0.41,  0.45,  0.4 ,  0.56,  0.59,\n",
       "         0.5 ,  0.5 ,  0.61,  0.61,  0.61,  0.66,  0.66,  0.68,  0.68,\n",
       "         0.69,  0.6 ,  0.71,  0.74,  0.7 ,  0.7 ,  0.7 ,  0.43,  0.47,\n",
       "         0.47,  0.49,  0.55,  0.56,  0.58,  0.62,  0.6 ,  0.73,  0.74,\n",
       "         0.7 ,  0.7 ,  0.7 ,  0.61,  0.6 ,  0.6 ,  0.6 ,  0.72,  0.72,\n",
       "         0.73,  0.51,  0.56,  0.69,  0.69,  0.71,  0.73,  0.57,  0.58,\n",
       "         0.65,  0.65,  0.72,  0.7 ,  0.58,  0.64,  0.65,  0.65,  0.65,\n",
       "         0.71,  0.43,  0.49,  0.58,  0.59,  0.64,  0.65,  0.6 ,  0.72,\n",
       "         0.74,  0.74,  0.67,  0.67,  0.67,  0.66,  0.67,  0.68,  0.6 ,\n",
       "         0.7 ,  0.47,  0.49,  0.59,  0.59,  0.59,  0.6 ,  0.6 ,  0.6 ,\n",
       "         0.75,  0.7 ,  0.7 ,  0.7 ,  0.53,  0.56,  0.6 ,  0.6 ,  0.71,\n",
       "         0.72,  0.72,  0.75,  0.75,  0.7 ,  0.7 ,  0.69,  0.75,  0.7 ,\n",
       "         0.7 ,  0.5 ,  0.71,  0.72,  0.72,  0.61,  0.64,  0.6 ,  0.71,\n",
       "         0.71,  0.71,  0.73,  0.73,  0.73,  0.73,  0.52,  0.54,  0.56,\n",
       "         0.61,  0.63,  0.67,  0.67,  0.68,  0.72,  0.72,  0.73,  0.73,\n",
       "         0.7 ,  0.52,  0.52,  0.54,  0.59,  0.61,  0.63,  0.68,  0.69,  0.72]),\n",
       " array([ 0.48,  0.48,  0.48,  0.48,  0.48,  0.54,  0.54,  0.54,  0.54,\n",
       "         0.54,  0.57,  0.57,  0.57,  0.57,  0.57,  0.59,  0.59,  0.59,\n",
       "         0.59,  0.59,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.62,  0.62,\n",
       "         0.62,  0.62,  0.62,  0.63,  0.63,  0.63,  0.63,  0.63,  0.65,\n",
       "         0.65,  0.65,  0.65,  0.65,  0.67,  0.67,  0.67,  0.67,  0.67,\n",
       "         0.68,  0.68,  0.68,  0.68,  0.68,  0.69,  0.69,  0.69,  0.69,\n",
       "         0.69,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.71,  0.71,  0.71,\n",
       "         0.71,  0.72,  0.72,  0.72,  0.72,  0.72,  0.72,  0.73,  0.73,\n",
       "         0.73,  0.73,  0.73,  0.74,  0.74,  0.74,  0.74,  0.74,  0.75,\n",
       "         0.75,  0.75,  0.75,  0.75,  0.76,  0.76,  0.76,  0.76,  0.76,\n",
       "         0.77,  0.77,  0.77,  0.77,  0.77,  0.78,  0.78,  0.78,  0.78,\n",
       "         0.78,  0.79,  0.79,  0.79,  0.79,  0.79,  0.8 ,  0.8 ,  0.8 ,\n",
       "         0.81,  0.81,  0.81,  0.81,  0.81,  0.82,  0.82,  0.82,  0.82,\n",
       "         0.82,  0.83,  0.83,  0.83,  0.83,  0.83,  0.84,  0.84,  0.84,\n",
       "         0.84,  0.84,  0.86,  0.86,  0.86,  0.86,  0.86,  0.88,  0.88,\n",
       "         0.88,  0.88,  0.88,  0.9 ,  0.9 ,  0.91,  0.92,  0.92,  0.92,\n",
       "         0.92,  0.96,  0.97,  0.97,  0.97,  0.97]),\n",
       " array([ 0.27,  0.46,  0.47,  0.47,  0.5 ,  0.49,  0.52,  0.59,  0.59,\n",
       "         0.63,  0.57,  0.61,  0.65,  0.67,  0.69,  0.59,  0.63,  0.64,\n",
       "         0.67,  0.68,  0.63,  0.64,  0.65,  0.67,  0.68,  0.43,  0.45,\n",
       "         0.48,  0.55,  0.58,  0.77,  0.77,  0.78,  0.82,  0.84,  0.63,\n",
       "         0.64,  0.65,  0.66,  0.67,  0.35,  0.48,  0.59,  0.7 ,  0.7 ,\n",
       "         0.69,  0.69,  0.72,  0.72,  0.72,  0.74,  0.76,  0.77,  0.79,\n",
       "         0.79,  0.78,  0.81,  0.82,  0.83,  0.87,  0.84,  0.91,  0.94,\n",
       "         0.95,  0.4 ,  0.78,  0.78,  0.79,  0.79,  0.81,  0.77,  0.77,\n",
       "         0.78,  0.78,  0.78,  0.75,  0.75,  0.78,  0.79,  0.82,  0.73,\n",
       "         0.75,  0.75,  0.75,  0.76,  0.66,  0.68,  0.71,  0.71,  0.72,\n",
       "         0.53,  0.54,  0.57,  0.63,  0.63,  0.73,  0.73,  0.73,  0.74,\n",
       "         0.75,  0.67,  0.71,  0.73,  0.73,  0.73,  0.88,  0.95,  1.  ,\n",
       "         0.67,  0.68,  0.68,  0.71,  0.71,  0.68,  0.71,  0.72,  0.73,\n",
       "         0.74,  0.79,  0.82,  0.82,  0.83,  0.84,  0.92,  0.93,  0.93,\n",
       "         0.93,  0.95,  0.84,  0.84,  0.87,  0.87,  0.87,  0.87,  0.87,\n",
       "         0.88,  0.89,  0.91,  0.74,  0.9 ,  0.93,  0.65,  0.79,  0.84,\n",
       "         0.8 ,  0.93,  0.82,  0.83,  0.89,  0.9 ]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels1, labels2, labels1_val, labels2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "import keras.optimizers as Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "img_in = Input(shape=(160, 128, 3), name='img_in')\n",
    "\n",
    "x = img_in\n",
    "\n",
    "x = Convolution2D(24, (5,5), strides=(2,2), activation='relu')(x)       # 24 features, 5 pixel x 5 pixel kernel (convolution, feauture) window, 2wx2h stride, relu activation\n",
    "x = Convolution2D(32, (5,5), strides=(2,2), activation='relu')(x)       # 32 features, 5px5p kernel window, 2wx2h stride, relu activatiion\n",
    "x = Convolution2D(64, (5,5), strides=(2,2), activation='relu')(x)       # 64 features, 5px5p kernal window, 2wx2h stride, relu\n",
    "x = Convolution2D(64, (3,3), strides=(2,2), activation='relu')(x)       # 64 features, 3px3p kernal window, 2wx2h stride, relu\n",
    "x = Convolution2D(64, (3,3), strides=(1,1), activation='relu')(x)       # 64 features, 3px3p kernal window, 1wx1h stride, relu\n",
    "\n",
    "# Possibly add MaxPooling (will make it less sensitive to position in image).  Camera angle fixed, so may not to be needed\n",
    "\n",
    "x = Flatten(name='flattened')(x)                                        # Flatten to 1D (Fully connected)\n",
    "x = Dense(100, activation='relu')(x)                                    # Classify the data into 100 features, make all negatives 0\n",
    "x = Dropout(.1)(x)                                                      # Randomly drop out (turn off) 10% of the neurons (Prevent overfitting)\n",
    "x = Dense(50, activation='relu')(x)                                     # Classify the data into 50 features, make all negatives 0\n",
    "x = Dropout(.1)(x)                                                      # Randomly drop out 10% of the neurons (Prevent overfitting)\n",
    "\n",
    "#categorical output\n",
    "out1 = Dense(10, activation='relu')(x)\n",
    "out1 = Dense(1, activation='linear')(out1)\n",
    "\n",
    "out2 = Dense(10, activation='relu')(x)\n",
    "out2 = Dense(1, activation='linear')(out2)\n",
    "\n",
    "model = Model(inputs=[img_in], outputs=[out1, out2])\n",
    "model.compile(loss=['mse', 'mse'], optimizer='adadelta', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "img_in (InputLayer)              (None, 160, 128, 3)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 78, 62, 24)    1824        img_in[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 37, 29, 32)    19232       conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 17, 13, 64)    51264       conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 8, 6, 64)      36928       conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 6, 4, 64)      36928       conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flattened (Flatten)              (None, 1536)          0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 100)           153700      flattened[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 100)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 50)            5050        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 50)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            510         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 10)            510         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 1)             11          dense_5[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 305,968\n",
      "Trainable params: 305,968\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "199/199 [==============================] - 2s - loss: 0.0461 - dense_4_loss: 0.0248 - dense_6_loss: 0.0213 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 2/50\n",
      "199/199 [==============================] - 2s - loss: 0.0427 - dense_4_loss: 0.0223 - dense_6_loss: 0.0204 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 3/50\n",
      "199/199 [==============================] - 2s - loss: 0.0376 - dense_4_loss: 0.0195 - dense_6_loss: 0.0181 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 4/50\n",
      "199/199 [==============================] - 2s - loss: 0.0318 - dense_4_loss: 0.0169 - dense_6_loss: 0.0148 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 5/50\n",
      "199/199 [==============================] - 2s - loss: 0.0313 - dense_4_loss: 0.0156 - dense_6_loss: 0.0157 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 6/50\n",
      "199/199 [==============================] - 2s - loss: 0.0309 - dense_4_loss: 0.0163 - dense_6_loss: 0.0146 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 7/50\n",
      "199/199 [==============================] - 2s - loss: 0.0318 - dense_4_loss: 0.0156 - dense_6_loss: 0.0162 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 8/50\n",
      "199/199 [==============================] - 2s - loss: 0.0272 - dense_4_loss: 0.0135 - dense_6_loss: 0.0137 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 9/50\n",
      "199/199 [==============================] - 2s - loss: 0.0277 - dense_4_loss: 0.0134 - dense_6_loss: 0.0142 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 10/50\n",
      "199/199 [==============================] - 2s - loss: 0.0236 - dense_4_loss: 0.0113 - dense_6_loss: 0.0123 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 11/50\n",
      "199/199 [==============================] - 3s - loss: 0.0260 - dense_4_loss: 0.0131 - dense_6_loss: 0.0128 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 12/50\n",
      "199/199 [==============================] - 3s - loss: 0.0198 - dense_4_loss: 0.0092 - dense_6_loss: 0.0106 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 13/50\n",
      "199/199 [==============================] - 3s - loss: 0.0227 - dense_4_loss: 0.0113 - dense_6_loss: 0.0115 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 14/50\n",
      "199/199 [==============================] - 3s - loss: 0.0195 - dense_4_loss: 0.0098 - dense_6_loss: 0.0097 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 15/50\n",
      "199/199 [==============================] - 3s - loss: 0.0154 - dense_4_loss: 0.0070 - dense_6_loss: 0.0084 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 16/50\n",
      "199/199 [==============================] - 3s - loss: 0.0137 - dense_4_loss: 0.0068 - dense_6_loss: 0.0069 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 17/50\n",
      "199/199 [==============================] - 3s - loss: 0.0111 - dense_4_loss: 0.0057 - dense_6_loss: 0.0053 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 18/50\n",
      "199/199 [==============================] - 3s - loss: 0.0103 - dense_4_loss: 0.0057 - dense_6_loss: 0.0046 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 19/50\n",
      "199/199 [==============================] - 3s - loss: 0.0098 - dense_4_loss: 0.0049 - dense_6_loss: 0.0049 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 20/50\n",
      "199/199 [==============================] - 3s - loss: 0.0096 - dense_4_loss: 0.0058 - dense_6_loss: 0.0038 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 21/50\n",
      "199/199 [==============================] - 3s - loss: 0.0080 - dense_4_loss: 0.0042 - dense_6_loss: 0.0038 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 22/50\n",
      "199/199 [==============================] - 3s - loss: 0.0081 - dense_4_loss: 0.0044 - dense_6_loss: 0.0037 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 23/50\n",
      "199/199 [==============================] - 3s - loss: 0.0066 - dense_4_loss: 0.0034 - dense_6_loss: 0.0032 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 24/50\n",
      "199/199 [==============================] - 3s - loss: 0.0064 - dense_4_loss: 0.0032 - dense_6_loss: 0.0032 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 25/50\n",
      "199/199 [==============================] - 3s - loss: 0.0062 - dense_4_loss: 0.0033 - dense_6_loss: 0.0028 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 26/50\n",
      "199/199 [==============================] - 3s - loss: 0.0056 - dense_4_loss: 0.0032 - dense_6_loss: 0.0024 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 27/50\n",
      "199/199 [==============================] - 3s - loss: 0.0048 - dense_4_loss: 0.0024 - dense_6_loss: 0.0024 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 28/50\n",
      "199/199 [==============================] - 3s - loss: 0.0049 - dense_4_loss: 0.0027 - dense_6_loss: 0.0022 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 29/50\n",
      "199/199 [==============================] - 3s - loss: 0.0044 - dense_4_loss: 0.0022 - dense_6_loss: 0.0023 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 30/50\n",
      "199/199 [==============================] - 3s - loss: 0.0042 - dense_4_loss: 0.0022 - dense_6_loss: 0.0020 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 31/50\n",
      "199/199 [==============================] - 3s - loss: 0.0042 - dense_4_loss: 0.0024 - dense_6_loss: 0.0017 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 32/50\n",
      "199/199 [==============================] - 3s - loss: 0.0040 - dense_4_loss: 0.0022 - dense_6_loss: 0.0018 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 33/50\n",
      "199/199 [==============================] - 3s - loss: 0.0031 - dense_4_loss: 0.0016 - dense_6_loss: 0.0015 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 34/50\n",
      "199/199 [==============================] - 3s - loss: 0.0030 - dense_4_loss: 0.0017 - dense_6_loss: 0.0013 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 35/50\n",
      "199/199 [==============================] - 3s - loss: 0.0032 - dense_4_loss: 0.0015 - dense_6_loss: 0.0017 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 36/50\n",
      "199/199 [==============================] - 3s - loss: 0.0032 - dense_4_loss: 0.0016 - dense_6_loss: 0.0016 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 37/50\n",
      "199/199 [==============================] - 3s - loss: 0.0028 - dense_4_loss: 0.0016 - dense_6_loss: 0.0012 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 38/50\n",
      "199/199 [==============================] - 3s - loss: 0.0024 - dense_4_loss: 0.0012 - dense_6_loss: 0.0012 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 39/50\n",
      "199/199 [==============================] - 3s - loss: 0.0025 - dense_4_loss: 0.0011 - dense_6_loss: 0.0014 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 40/50\n",
      "199/199 [==============================] - 3s - loss: 0.0027 - dense_4_loss: 0.0011 - dense_6_loss: 0.0016 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 41/50\n",
      "199/199 [==============================] - 3s - loss: 0.0022 - dense_4_loss: 0.0010 - dense_6_loss: 0.0012 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 42/50\n",
      "199/199 [==============================] - 3s - loss: 0.0025 - dense_4_loss: 0.0014 - dense_6_loss: 0.0011 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 43/50\n",
      "199/199 [==============================] - 3s - loss: 0.0024 - dense_4_loss: 0.0012 - dense_6_loss: 0.0013 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 44/50\n",
      "199/199 [==============================] - 3s - loss: 0.0020 - dense_4_loss: 0.0010 - dense_6_loss: 0.0010 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00        \n",
      "Epoch 45/50\n",
      "199/199 [==============================] - 3s - loss: 0.0019 - dense_4_loss: 0.0010 - dense_6_loss: 9.2324e-04 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00         \n",
      "Epoch 46/50\n",
      "199/199 [==============================] - 3s - loss: 0.0021 - dense_4_loss: 9.1348e-04 - dense_6_loss: 0.0012 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199/199 [==============================] - 3s - loss: 0.0018 - dense_4_loss: 8.2154e-04 - dense_6_loss: 9.6966e-04 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 48/50\n",
      "199/199 [==============================] - 3s - loss: 0.0021 - dense_4_loss: 0.0011 - dense_6_loss: 0.0010 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n",
      "Epoch 49/50\n",
      "199/199 [==============================] - 3s - loss: 0.0018 - dense_4_loss: 8.3762e-04 - dense_6_loss: 9.9911e-04 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00   \n",
      "Epoch 50/50\n",
      "199/199 [==============================] - 3s - loss: 0.0018 - dense_4_loss: 8.5748e-04 - dense_6_loss: 9.6699e-04 - dense_4_acc: 0.0000e+00 - dense_6_acc: 0.0000e+00     \n"
     ]
    }
   ],
   "source": [
    "h = model.fit(images, [labels1, labels2], batch_size=1, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d232c4ab00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d2337b7780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print History graph\n",
    "historydf = pd.DataFrame(h.history, index=h.epoch)\n",
    "historydf.plot(ylim=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 0.63037479],\n",
       "         [ 0.67991465],\n",
       "         [ 0.66024989],\n",
       "         [ 0.58591962],\n",
       "         [ 0.67588389],\n",
       "         [ 0.55845225],\n",
       "         [ 0.64076358],\n",
       "         [ 0.60391307],\n",
       "         [ 0.53961205],\n",
       "         [ 0.52192545],\n",
       "         [ 0.60388935],\n",
       "         [ 0.59626907],\n",
       "         [ 0.57277763],\n",
       "         [ 0.58463639],\n",
       "         [ 0.61831689],\n",
       "         [ 0.65965104],\n",
       "         [ 0.66984677],\n",
       "         [ 0.61356133],\n",
       "         [ 0.60743427],\n",
       "         [ 0.68456727],\n",
       "         [ 0.56419867],\n",
       "         [ 0.62983072],\n",
       "         [ 0.5894627 ],\n",
       "         [ 0.60286695],\n",
       "         [ 0.50245452],\n",
       "         [ 0.59017462],\n",
       "         [ 0.61069894],\n",
       "         [ 0.61054063],\n",
       "         [ 0.63929588],\n",
       "         [ 0.65325093],\n",
       "         [ 0.5999462 ],\n",
       "         [ 0.62564409],\n",
       "         [ 0.54494905],\n",
       "         [ 0.50752038],\n",
       "         [ 0.57712835],\n",
       "         [ 0.6478706 ],\n",
       "         [ 0.71670532],\n",
       "         [ 0.62005097],\n",
       "         [ 0.6296801 ],\n",
       "         [ 0.47781259],\n",
       "         [ 0.63340807],\n",
       "         [ 0.67892009],\n",
       "         [ 0.73433346],\n",
       "         [ 0.53115714],\n",
       "         [ 0.56832242],\n",
       "         [ 0.63688338],\n",
       "         [ 0.59092462],\n",
       "         [ 0.59004122],\n",
       "         [ 0.59992701],\n",
       "         [ 0.62602699],\n",
       "         [ 0.62185913],\n",
       "         [ 0.58095694],\n",
       "         [ 0.62207007],\n",
       "         [ 0.6107626 ],\n",
       "         [ 0.52959895],\n",
       "         [ 0.61858672],\n",
       "         [ 0.49279928],\n",
       "         [ 0.57742649],\n",
       "         [ 0.55919826],\n",
       "         [ 0.53976411],\n",
       "         [ 0.66942173],\n",
       "         [ 0.60952723],\n",
       "         [ 0.57976174],\n",
       "         [ 0.59624851],\n",
       "         [ 0.6083594 ],\n",
       "         [ 0.58816087],\n",
       "         [ 0.62134993],\n",
       "         [ 0.60057735],\n",
       "         [ 0.61914861],\n",
       "         [ 0.62502068],\n",
       "         [ 0.62220335],\n",
       "         [ 0.6610198 ],\n",
       "         [ 0.6718455 ],\n",
       "         [ 0.6221087 ],\n",
       "         [ 0.59359139],\n",
       "         [ 0.65069991],\n",
       "         [ 0.60558981],\n",
       "         [ 0.51832974],\n",
       "         [ 0.58723325],\n",
       "         [ 0.48833984],\n",
       "         [ 0.66527247],\n",
       "         [ 0.57395512],\n",
       "         [ 0.64711517],\n",
       "         [ 0.60895824],\n",
       "         [ 0.55891365],\n",
       "         [ 0.68226588],\n",
       "         [ 0.67413676],\n",
       "         [ 0.67502075],\n",
       "         [ 0.55818313],\n",
       "         [ 0.64194918],\n",
       "         [ 0.60191667],\n",
       "         [ 0.65834957],\n",
       "         [ 0.57250643],\n",
       "         [ 0.68329078],\n",
       "         [ 0.68922102],\n",
       "         [ 0.62384653],\n",
       "         [ 0.65671271],\n",
       "         [ 0.68656409],\n",
       "         [ 0.59183329],\n",
       "         [ 0.61298037],\n",
       "         [ 0.65001351],\n",
       "         [ 0.57854533],\n",
       "         [ 0.66271126],\n",
       "         [ 0.6048103 ],\n",
       "         [ 0.57317388],\n",
       "         [ 0.60142952],\n",
       "         [ 0.61723065],\n",
       "         [ 0.59590781],\n",
       "         [ 0.68096697],\n",
       "         [ 0.61729234],\n",
       "         [ 0.65350527],\n",
       "         [ 0.61166149],\n",
       "         [ 0.68171763],\n",
       "         [ 0.6443246 ],\n",
       "         [ 0.65751207],\n",
       "         [ 0.62513566],\n",
       "         [ 0.6836589 ],\n",
       "         [ 0.62972057],\n",
       "         [ 0.60862696],\n",
       "         [ 0.69446701],\n",
       "         [ 0.63302499],\n",
       "         [ 0.62312436],\n",
       "         [ 0.62177497],\n",
       "         [ 0.58543563],\n",
       "         [ 0.58892542],\n",
       "         [ 0.66283923],\n",
       "         [ 0.5623371 ],\n",
       "         [ 0.62178564],\n",
       "         [ 0.6375764 ],\n",
       "         [ 0.66484076],\n",
       "         [ 0.54404116],\n",
       "         [ 0.53577447],\n",
       "         [ 0.54232413],\n",
       "         [ 0.59559476],\n",
       "         [ 0.71450913],\n",
       "         [ 0.61504996],\n",
       "         [ 0.65957612],\n",
       "         [ 0.65982294],\n",
       "         [ 0.67411005],\n",
       "         [ 0.48961103],\n",
       "         [ 0.61724299],\n",
       "         [ 0.64589536],\n",
       "         [ 0.57806158],\n",
       "         [ 0.70785177],\n",
       "         [ 0.60946059],\n",
       "         [ 0.6556288 ],\n",
       "         [ 0.65058166],\n",
       "         [ 0.61212701],\n",
       "         [ 0.57880706],\n",
       "         [ 0.62118477]], dtype=float32), array([[ 0.58776665],\n",
       "         [ 0.66799748],\n",
       "         [ 0.70686007],\n",
       "         [ 0.64573479],\n",
       "         [ 0.52035379],\n",
       "         [ 0.66982234],\n",
       "         [ 0.60903192],\n",
       "         [ 0.68761301],\n",
       "         [ 0.54317176],\n",
       "         [ 0.55377471],\n",
       "         [ 0.57441437],\n",
       "         [ 0.68107784],\n",
       "         [ 0.65925539],\n",
       "         [ 0.66436243],\n",
       "         [ 0.64549589],\n",
       "         [ 0.64515173],\n",
       "         [ 0.65265185],\n",
       "         [ 0.6827569 ],\n",
       "         [ 0.57061672],\n",
       "         [ 0.66334224],\n",
       "         [ 0.62366164],\n",
       "         [ 0.61599445],\n",
       "         [ 0.57261622],\n",
       "         [ 0.65892136],\n",
       "         [ 0.64112699],\n",
       "         [ 0.51038849],\n",
       "         [ 0.60561526],\n",
       "         [ 0.60135341],\n",
       "         [ 0.60537565],\n",
       "         [ 0.6507858 ],\n",
       "         [ 0.67801476],\n",
       "         [ 0.66890931],\n",
       "         [ 0.66196632],\n",
       "         [ 0.63941908],\n",
       "         [ 0.6691317 ],\n",
       "         [ 0.65661389],\n",
       "         [ 0.66928232],\n",
       "         [ 0.66838598],\n",
       "         [ 0.62455928],\n",
       "         [ 0.67231703],\n",
       "         [ 0.49697033],\n",
       "         [ 0.54978359],\n",
       "         [ 0.67651784],\n",
       "         [ 0.61107242],\n",
       "         [ 0.66177905],\n",
       "         [ 0.67790353],\n",
       "         [ 0.64267135],\n",
       "         [ 0.58968496],\n",
       "         [ 0.65320075],\n",
       "         [ 0.50478804],\n",
       "         [ 0.5892638 ],\n",
       "         [ 0.57206821],\n",
       "         [ 0.64117026],\n",
       "         [ 0.64464474],\n",
       "         [ 0.61288297],\n",
       "         [ 0.66706109],\n",
       "         [ 0.61493248],\n",
       "         [ 0.67769706],\n",
       "         [ 0.63048804],\n",
       "         [ 0.69268322],\n",
       "         [ 0.67016613],\n",
       "         [ 0.61513543],\n",
       "         [ 0.650056  ],\n",
       "         [ 0.56266391],\n",
       "         [ 0.58881152],\n",
       "         [ 0.66720057],\n",
       "         [ 0.58153141],\n",
       "         [ 0.54714346],\n",
       "         [ 0.58142221],\n",
       "         [ 0.65152323],\n",
       "         [ 0.57966471],\n",
       "         [ 0.63117391],\n",
       "         [ 0.65533769],\n",
       "         [ 0.65337729],\n",
       "         [ 0.62043971],\n",
       "         [ 0.66135335],\n",
       "         [ 0.60788667],\n",
       "         [ 0.62996221],\n",
       "         [ 0.63011253],\n",
       "         [ 0.65965188],\n",
       "         [ 0.5902189 ],\n",
       "         [ 0.65269363],\n",
       "         [ 0.64862192],\n",
       "         [ 0.67200959],\n",
       "         [ 0.6285063 ],\n",
       "         [ 0.61595893],\n",
       "         [ 0.62211537],\n",
       "         [ 0.64354455],\n",
       "         [ 0.56891024],\n",
       "         [ 0.60848975],\n",
       "         [ 0.5157218 ],\n",
       "         [ 0.54557937],\n",
       "         [ 0.62327784],\n",
       "         [ 0.56769979],\n",
       "         [ 0.62587166],\n",
       "         [ 0.66411626],\n",
       "         [ 0.58156514],\n",
       "         [ 0.64169693],\n",
       "         [ 0.58177495],\n",
       "         [ 0.62691581],\n",
       "         [ 0.60592449],\n",
       "         [ 0.63168776],\n",
       "         [ 0.64612436],\n",
       "         [ 0.58019054],\n",
       "         [ 0.56866068],\n",
       "         [ 0.62521434],\n",
       "         [ 0.64345419],\n",
       "         [ 0.65571439],\n",
       "         [ 0.53590512],\n",
       "         [ 0.58554435],\n",
       "         [ 0.6256516 ],\n",
       "         [ 0.52939761],\n",
       "         [ 0.62196016],\n",
       "         [ 0.61869538],\n",
       "         [ 0.58699119],\n",
       "         [ 0.57238388],\n",
       "         [ 0.65098214],\n",
       "         [ 0.63206077],\n",
       "         [ 0.63392299],\n",
       "         [ 0.67674792],\n",
       "         [ 0.65593195],\n",
       "         [ 0.62014198],\n",
       "         [ 0.67030525],\n",
       "         [ 0.65940374],\n",
       "         [ 0.67518818],\n",
       "         [ 0.67821509],\n",
       "         [ 0.52518916],\n",
       "         [ 0.67996711],\n",
       "         [ 0.62253785],\n",
       "         [ 0.64819622],\n",
       "         [ 0.66818368],\n",
       "         [ 0.62862575],\n",
       "         [ 0.60514522],\n",
       "         [ 0.4940955 ],\n",
       "         [ 0.63084304],\n",
       "         [ 0.67904001],\n",
       "         [ 0.66618735],\n",
       "         [ 0.65106231],\n",
       "         [ 0.63086152],\n",
       "         [ 0.62434214],\n",
       "         [ 0.67160738],\n",
       "         [ 0.50989223],\n",
       "         [ 0.58205885],\n",
       "         [ 0.64475334],\n",
       "         [ 0.65420663],\n",
       "         [ 0.68194461],\n",
       "         [ 0.62096971],\n",
       "         [ 0.65282577],\n",
       "         [ 0.58589566],\n",
       "         [ 0.59230661]], dtype=float32)],\n",
       " array([ 0.27,  0.46,  0.47,  0.47,  0.5 ,  0.49,  0.52,  0.59,  0.59,\n",
       "         0.63,  0.57,  0.61,  0.65,  0.67,  0.69,  0.59,  0.63,  0.64,\n",
       "         0.67,  0.68,  0.63,  0.64,  0.65,  0.67,  0.68,  0.43,  0.45,\n",
       "         0.48,  0.55,  0.58,  0.77,  0.77,  0.78,  0.82,  0.84,  0.63,\n",
       "         0.64,  0.65,  0.66,  0.67,  0.35,  0.48,  0.59,  0.7 ,  0.7 ,\n",
       "         0.69,  0.69,  0.72,  0.72,  0.72,  0.74,  0.76,  0.77,  0.79,\n",
       "         0.79,  0.78,  0.81,  0.82,  0.83,  0.87,  0.84,  0.91,  0.94,\n",
       "         0.95,  0.4 ,  0.78,  0.78,  0.79,  0.79,  0.81,  0.77,  0.77,\n",
       "         0.78,  0.78,  0.78,  0.75,  0.75,  0.78,  0.79,  0.82,  0.73,\n",
       "         0.75,  0.75,  0.75,  0.76,  0.66,  0.68,  0.71,  0.71,  0.72,\n",
       "         0.53,  0.54,  0.57,  0.63,  0.63,  0.73,  0.73,  0.73,  0.74,\n",
       "         0.75,  0.67,  0.71,  0.73,  0.73,  0.73,  0.88,  0.95,  1.  ,\n",
       "         0.67,  0.68,  0.68,  0.71,  0.71,  0.68,  0.71,  0.72,  0.73,\n",
       "         0.74,  0.79,  0.82,  0.82,  0.83,  0.84,  0.92,  0.93,  0.93,\n",
       "         0.93,  0.95,  0.84,  0.84,  0.87,  0.87,  0.87,  0.87,  0.87,\n",
       "         0.88,  0.89,  0.91,  0.74,  0.9 ,  0.93,  0.65,  0.79,  0.84,\n",
       "         0.8 ,  0.93,  0.82,  0.83,  0.89,  0.9 ]),\n",
       " array([ 0.48,  0.48,  0.48,  0.48,  0.48,  0.54,  0.54,  0.54,  0.54,\n",
       "         0.54,  0.57,  0.57,  0.57,  0.57,  0.57,  0.59,  0.59,  0.59,\n",
       "         0.59,  0.59,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.6 ,  0.62,  0.62,\n",
       "         0.62,  0.62,  0.62,  0.63,  0.63,  0.63,  0.63,  0.63,  0.65,\n",
       "         0.65,  0.65,  0.65,  0.65,  0.67,  0.67,  0.67,  0.67,  0.67,\n",
       "         0.68,  0.68,  0.68,  0.68,  0.68,  0.69,  0.69,  0.69,  0.69,\n",
       "         0.69,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.7 ,  0.71,  0.71,  0.71,\n",
       "         0.71,  0.72,  0.72,  0.72,  0.72,  0.72,  0.72,  0.73,  0.73,\n",
       "         0.73,  0.73,  0.73,  0.74,  0.74,  0.74,  0.74,  0.74,  0.75,\n",
       "         0.75,  0.75,  0.75,  0.75,  0.76,  0.76,  0.76,  0.76,  0.76,\n",
       "         0.77,  0.77,  0.77,  0.77,  0.77,  0.78,  0.78,  0.78,  0.78,\n",
       "         0.78,  0.79,  0.79,  0.79,  0.79,  0.79,  0.8 ,  0.8 ,  0.8 ,\n",
       "         0.81,  0.81,  0.81,  0.81,  0.81,  0.82,  0.82,  0.82,  0.82,\n",
       "         0.82,  0.83,  0.83,  0.83,  0.83,  0.83,  0.84,  0.84,  0.84,\n",
       "         0.84,  0.84,  0.86,  0.86,  0.86,  0.86,  0.86,  0.88,  0.88,\n",
       "         0.88,  0.88,  0.88,  0.9 ,  0.9 ,  0.91,  0.92,  0.92,  0.92,\n",
       "         0.92,  0.96,  0.97,  0.97,  0.97,  0.97]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions\n",
    "all_preds = model.predict(images_val)\n",
    "\n",
    "all_preds, labels2_val, labels1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06742983], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "i = 0\n",
    "res = 0\n",
    "\n",
    "preds = all_preds[0] / all_preds[1]\n",
    "labels = labels1 / labels2\n",
    "for value in preds:\n",
    "    res = res + (value - labels[i])*(value - labels[i])\n",
    "    i = i + 1\n",
    "res/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-2x1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('test_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
